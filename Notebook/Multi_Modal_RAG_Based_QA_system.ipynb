{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "75YnIkHpM01z",
        "outputId": "211380ba-1c1a-4e84-abcc-f8fedd85aa4a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: fastapi in /usr/local/lib/python3.12/dist-packages (0.118.3)\n",
            "Requirement already satisfied: starlette<0.49.0,>=0.40.0 in /usr/local/lib/python3.12/dist-packages (from fastapi) (0.48.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4 in /usr/local/lib/python3.12/dist-packages (from fastapi) (2.12.3)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.12/dist-packages (from fastapi) (4.15.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (0.4.2)\n",
            "Requirement already satisfied: anyio<5,>=3.6.2 in /usr/local/lib/python3.12/dist-packages (from starlette<0.49.0,>=0.40.0->fastapi) (4.12.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.6.2->starlette<0.49.0,>=0.40.0->fastapi) (3.11)\n",
            "Requirement already satisfied: uvicorn[standard] in /usr/local/lib/python3.12/dist-packages (0.38.0)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]) (8.3.1)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]) (0.16.0)\n",
            "Collecting httptools>=0.6.3 (from uvicorn[standard])\n",
            "  Downloading httptools-0.7.1-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]) (1.2.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]) (6.0.3)\n",
            "Collecting uvloop>=0.15.1 (from uvicorn[standard])\n",
            "  Downloading uvloop-0.22.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting watchfiles>=0.13 (from uvicorn[standard])\n",
            "  Downloading watchfiles-1.1.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]) (15.0.1)\n",
            "Requirement already satisfied: anyio>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from watchfiles>=0.13->uvicorn[standard]) (4.12.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio>=3.0.0->watchfiles>=0.13->uvicorn[standard]) (3.11)\n",
            "Requirement already satisfied: typing_extensions>=4.5 in /usr/local/lib/python3.12/dist-packages (from anyio>=3.0.0->watchfiles>=0.13->uvicorn[standard]) (4.15.0)\n",
            "Downloading httptools-0.7.1-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (517 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m517.7/517.7 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading uvloop-0.22.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (4.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m72.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchfiles-1.1.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (456 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m456.8/456.8 kB\u001b[0m \u001b[31m27.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: uvloop, httptools, watchfiles\n",
            "Successfully installed httptools-0.7.1 uvloop-0.22.1 watchfiles-1.1.1\n",
            "Requirement already satisfied: python-multipart in /usr/local/lib/python3.12/dist-packages (0.0.20)\n",
            "Collecting chromadb\n",
            "  Downloading chromadb-1.3.6-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.2 kB)\n",
            "Collecting build>=1.0.3 (from chromadb)\n",
            "  Downloading build-1.3.0-py3-none-any.whl.metadata (5.6 kB)\n",
            "Requirement already satisfied: pydantic>=1.9 in /usr/local/lib/python3.12/dist-packages (from chromadb) (2.12.3)\n",
            "Collecting pybase64>=1.4.1 (from chromadb)\n",
            "  Downloading pybase64-1.4.3-cp312-cp312-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl.metadata (8.7 kB)\n",
            "Requirement already satisfied: uvicorn>=0.18.3 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.38.0)\n",
            "Requirement already satisfied: numpy>=1.22.5 in /usr/local/lib/python3.12/dist-packages (from chromadb) (2.0.2)\n",
            "Collecting posthog<6.0.0,>=2.4.0 (from chromadb)\n",
            "  Downloading posthog-5.4.0-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (4.15.0)\n",
            "Collecting onnxruntime>=1.14.1 (from chromadb)\n",
            "  Downloading onnxruntime-1.23.2-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (5.1 kB)\n",
            "Requirement already satisfied: opentelemetry-api>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.37.0)\n",
            "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.39.0-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.37.0)\n",
            "Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.12/dist-packages (from chromadb) (0.22.1)\n",
            "Collecting pypika>=0.48.9 (from chromadb)\n",
            "  Downloading PyPika-0.48.9.tar.gz (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (4.67.1)\n",
            "Requirement already satisfied: overrides>=7.3.1 in /usr/local/lib/python3.12/dist-packages (from chromadb) (7.7.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.12/dist-packages (from chromadb) (6.5.2)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.76.0)\n",
            "Collecting bcrypt>=4.0.1 (from chromadb)\n",
            "  Downloading bcrypt-5.0.0-cp39-abi3-manylinux_2_34_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (0.20.0)\n",
            "Collecting kubernetes>=28.1.0 (from chromadb)\n",
            "  Downloading kubernetes-34.1.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: tenacity>=8.2.3 in /usr/local/lib/python3.12/dist-packages (from chromadb) (9.1.2)\n",
            "Requirement already satisfied: pyyaml>=6.0.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (6.0.3)\n",
            "Collecting mmh3>=4.0.1 (from chromadb)\n",
            "  Downloading mmh3-5.2.0-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (14 kB)\n",
            "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.12/dist-packages (from chromadb) (3.11.4)\n",
            "Requirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (0.28.1)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (13.9.4)\n",
            "Requirement already satisfied: jsonschema>=4.19.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (4.25.1)\n",
            "Requirement already satisfied: packaging>=19.1 in /usr/local/lib/python3.12/dist-packages (from build>=1.0.3->chromadb) (25.0)\n",
            "Collecting pyproject_hooks (from build>=1.0.3->chromadb)\n",
            "  Downloading pyproject_hooks-1.2.0-py3-none-any.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.0->chromadb) (4.12.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.0->chromadb) (2025.11.12)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.0->chromadb) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.0->chromadb) (3.11)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.16.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb) (25.4.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb) (0.37.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb) (0.30.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (2.9.0.post0)\n",
            "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (2.43.0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (1.9.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (2.32.4)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (2.0.0)\n",
            "Collecting urllib3<2.4.0,>=1.24.2 (from kubernetes>=28.1.0->chromadb)\n",
            "  Downloading urllib3-2.3.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting durationpy>=0.7 (from kubernetes>=28.1.0->chromadb)\n",
            "  Downloading durationpy-0.10-py3-none-any.whl.metadata (340 bytes)\n",
            "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb) (25.9.23)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb) (5.29.5)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb) (1.14.0)\n",
            "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (8.7.0)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.57 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.72.0)\n",
            "Collecting opentelemetry-exporter-otlp-proto-common==1.39.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_common-1.39.0-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting opentelemetry-proto==1.39.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
            "  Downloading opentelemetry_proto-1.39.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting opentelemetry-sdk>=1.2.0 (from chromadb)\n",
            "  Downloading opentelemetry_sdk-1.39.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting opentelemetry-api>=1.2.0 (from chromadb)\n",
            "  Downloading opentelemetry_api-1.39.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting opentelemetry-semantic-conventions==0.60b0 (from opentelemetry-sdk>=1.2.0->chromadb)\n",
            "  Downloading opentelemetry_semantic_conventions-0.60b0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting backoff>=1.10.0 (from posthog<6.0.0,>=2.4.0->chromadb)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: distro>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from posthog<6.0.0,>=2.4.0->chromadb) (1.9.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=1.9->chromadb) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic>=1.9->chromadb) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=1.9->chromadb) (0.4.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->chromadb) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->chromadb) (2.19.2)\n",
            "Requirement already satisfied: huggingface-hub<2.0,>=0.16.4 in /usr/local/lib/python3.12/dist-packages (from tokenizers>=0.13.2->chromadb) (0.36.0)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer>=0.9.0->chromadb) (8.3.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer>=0.9.0->chromadb) (1.5.4)\n",
            "Requirement already satisfied: httptools>=0.6.3 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.7.1)\n",
            "Requirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.2.1)\n",
            "Requirement already satisfied: uvloop>=0.15.1 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.22.1)\n",
            "Requirement already satisfied: watchfiles>=0.13 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.1.1)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (15.0.1)\n",
            "Requirement already satisfied: cachetools<7.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (6.2.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.20.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2025.3.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (1.2.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.23.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->kubernetes>=28.1.0->chromadb) (3.4.4)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from requests-oauthlib->kubernetes>=28.1.0->chromadb) (3.3.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.6.1)\n",
            "Downloading chromadb-1.3.6-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (21.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.6/21.6 MB\u001b[0m \u001b[31m47.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bcrypt-5.0.0-cp39-abi3-manylinux_2_34_x86_64.whl (278 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.2/278.2 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading build-1.3.0-py3-none-any.whl (23 kB)\n",
            "Downloading kubernetes-34.1.0-py2.py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m28.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mmh3-5.2.0-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (103 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.3/103.3 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnxruntime-1.23.2-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (17.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.4/17.4 MB\u001b[0m \u001b[31m31.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_exporter_otlp_proto_grpc-1.39.0-py3-none-any.whl (19 kB)\n",
            "Downloading opentelemetry_exporter_otlp_proto_common-1.39.0-py3-none-any.whl (18 kB)\n",
            "Downloading opentelemetry_proto-1.39.0-py3-none-any.whl (72 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.5/72.5 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_sdk-1.39.0-py3-none-any.whl (132 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.4/132.4 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_api-1.39.0-py3-none-any.whl (66 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.4/66.4 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_semantic_conventions-0.60b0-py3-none-any.whl (219 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m220.0/220.0 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading posthog-5.4.0-py3-none-any.whl (105 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.4/105.4 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pybase64-1.4.3-cp312-cp312-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.6/71.6 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading durationpy-0.10-py3-none-any.whl (3.9 kB)\n",
            "Downloading urllib3-2.3.0-py3-none-any.whl (128 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.4/128.4 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyproject_hooks-1.2.0-py3-none-any.whl (10 kB)\n",
            "Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: pypika\n",
            "  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pypika: filename=pypika-0.48.9-py2.py3-none-any.whl size=53803 sha256=72bb5ec5ce4bbae644bd3547c5750878e65a68dfd1ea4ce3c47ef5b5411acf9c\n",
            "  Stored in directory: /root/.cache/pip/wheels/d5/3d/69/8d68d249cd3de2584f226e27fd431d6344f7d70fd856ebd01b\n",
            "Successfully built pypika\n",
            "Installing collected packages: pypika, durationpy, urllib3, pyproject_hooks, pybase64, opentelemetry-proto, mmh3, humanfriendly, bcrypt, backoff, opentelemetry-exporter-otlp-proto-common, opentelemetry-api, coloredlogs, build, posthog, opentelemetry-semantic-conventions, onnxruntime, opentelemetry-sdk, kubernetes, opentelemetry-exporter-otlp-proto-grpc, chromadb\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 2.5.0\n",
            "    Uninstalling urllib3-2.5.0:\n",
            "      Successfully uninstalled urllib3-2.5.0\n",
            "  Attempting uninstall: opentelemetry-proto\n",
            "    Found existing installation: opentelemetry-proto 1.37.0\n",
            "    Uninstalling opentelemetry-proto-1.37.0:\n",
            "      Successfully uninstalled opentelemetry-proto-1.37.0\n",
            "  Attempting uninstall: opentelemetry-exporter-otlp-proto-common\n",
            "    Found existing installation: opentelemetry-exporter-otlp-proto-common 1.37.0\n",
            "    Uninstalling opentelemetry-exporter-otlp-proto-common-1.37.0:\n",
            "      Successfully uninstalled opentelemetry-exporter-otlp-proto-common-1.37.0\n",
            "  Attempting uninstall: opentelemetry-api\n",
            "    Found existing installation: opentelemetry-api 1.37.0\n",
            "    Uninstalling opentelemetry-api-1.37.0:\n",
            "      Successfully uninstalled opentelemetry-api-1.37.0\n",
            "  Attempting uninstall: opentelemetry-semantic-conventions\n",
            "    Found existing installation: opentelemetry-semantic-conventions 0.58b0\n",
            "    Uninstalling opentelemetry-semantic-conventions-0.58b0:\n",
            "      Successfully uninstalled opentelemetry-semantic-conventions-0.58b0\n",
            "  Attempting uninstall: opentelemetry-sdk\n",
            "    Found existing installation: opentelemetry-sdk 1.37.0\n",
            "    Uninstalling opentelemetry-sdk-1.37.0:\n",
            "      Successfully uninstalled opentelemetry-sdk-1.37.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "opentelemetry-exporter-gcp-logging 1.11.0a0 requires opentelemetry-sdk<1.39.0,>=1.35.0, but you have opentelemetry-sdk 1.39.0 which is incompatible.\n",
            "opentelemetry-exporter-otlp-proto-http 1.37.0 requires opentelemetry-exporter-otlp-proto-common==1.37.0, but you have opentelemetry-exporter-otlp-proto-common 1.39.0 which is incompatible.\n",
            "opentelemetry-exporter-otlp-proto-http 1.37.0 requires opentelemetry-proto==1.37.0, but you have opentelemetry-proto 1.39.0 which is incompatible.\n",
            "opentelemetry-exporter-otlp-proto-http 1.37.0 requires opentelemetry-sdk~=1.37.0, but you have opentelemetry-sdk 1.39.0 which is incompatible.\n",
            "google-adk 1.20.0 requires opentelemetry-api<=1.37.0,>=1.37.0, but you have opentelemetry-api 1.39.0 which is incompatible.\n",
            "google-adk 1.20.0 requires opentelemetry-sdk<=1.37.0,>=1.37.0, but you have opentelemetry-sdk 1.39.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed backoff-2.2.1 bcrypt-5.0.0 build-1.3.0 chromadb-1.3.6 coloredlogs-15.0.1 durationpy-0.10 humanfriendly-10.0 kubernetes-34.1.0 mmh3-5.2.0 onnxruntime-1.23.2 opentelemetry-api-1.39.0 opentelemetry-exporter-otlp-proto-common-1.39.0 opentelemetry-exporter-otlp-proto-grpc-1.39.0 opentelemetry-proto-1.39.0 opentelemetry-sdk-1.39.0 opentelemetry-semantic-conventions-0.60b0 posthog-5.4.0 pybase64-1.4.3 pypika-0.48.9 pyproject_hooks-1.2.0 urllib3-2.3.0\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.12/dist-packages (5.1.2)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.57.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.67.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (2.9.0+cu126)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.16.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (0.36.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (11.3.0)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.15.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.20.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.4)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.2.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.5.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2025.11.3)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.7.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2025.11.12)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (4.67.1)\n",
            "Collecting PyMuPDF\n",
            "  Downloading pymupdf-1.26.6-cp310-abi3-manylinux_2_28_x86_64.whl.metadata (3.4 kB)\n",
            "Downloading pymupdf-1.26.6-cp310-abi3-manylinux_2_28_x86_64.whl (24.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.1/24.1 MB\u001b[0m \u001b[31m105.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyMuPDF\n",
            "Successfully installed PyMuPDF-1.26.6\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.12/dist-packages (11.3.0)\n",
            "Collecting pytesseract\n",
            "  Downloading pytesseract-0.3.13-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.12/dist-packages (from pytesseract) (25.0)\n",
            "Requirement already satisfied: Pillow>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from pytesseract) (11.3.0)\n",
            "Downloading pytesseract-0.3.13-py3-none-any.whl (14 kB)\n",
            "Installing collected packages: pytesseract\n",
            "Successfully installed pytesseract-0.3.13\n",
            "Requirement already satisfied: sqlalchemy in /usr/local/lib/python3.12/dist-packages (2.0.44)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions>=4.6.0 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy) (4.15.0)\n",
            "Requirement already satisfied: aiofiles in /usr/local/lib/python3.12/dist-packages (24.1.0)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.12/dist-packages (1.2.1)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.3)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.12/dist-packages (1.12.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.12/dist-packages (0.2.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.36.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2025.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.7.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from accelerate) (2.9.0+cu126)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.2.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.5.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.11.12)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.3)\n",
            "Requirement already satisfied: nest_asyncio in /usr/local/lib/python3.12/dist-packages (1.6.0)\n",
            "Collecting pyngrok\n",
            "  Downloading pyngrok-7.5.0-py3-none-any.whl.metadata (8.1 kB)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.12/dist-packages (from pyngrok) (6.0.3)\n",
            "Downloading pyngrok-7.5.0-py3-none-any.whl (24 kB)\n",
            "Installing collected packages: pyngrok\n",
            "Successfully installed pyngrok-7.5.0\n"
          ]
        }
      ],
      "source": [
        "!pip install fastapi\n",
        "!pip install uvicorn[standard]\n",
        "!pip install python-multipart\n",
        "!pip install chromadb\n",
        "!pip install sentence-transformers\n",
        "!pip install tqdm\n",
        "!pip install PyMuPDF\n",
        "!pip install pillow\n",
        "!pip install pytesseract\n",
        "!pip install sqlalchemy\n",
        "!pip install aiofiles\n",
        "!pip install python-dotenv\n",
        "!pip install transformers accelerate sentencepiece\n",
        "!pip install nest_asyncio\n",
        "!pip install pyngrok\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ngrok setup"
      ],
      "metadata": {
        "id": "Qiayq9lPLJQ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from getpass import getpass\n",
        "import os\n",
        "\n",
        "# This will NOT show your token when you type it\n",
        "token = getpass(\"Paste your ngrok token (input hidden): \")\n",
        "\n",
        "# Store it in an env var for later use\n",
        "os.environ[\"NGROK_AUTH_TOKEN\"] = token\n",
        "\n",
        "print(\"Token stored in environment (not printed).\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XbBPRvFBzjiV",
        "outputId": "e63df641-29a2-4c3e-cf91-27ca1eaf3702"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Paste your ngrok token (input hidden): ··········\n",
            "Token stored in environment (not printed).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "import os\n",
        "\n",
        "NGROK_TOKEN = os.environ.get(\"NGROK_AUTH_TOKEN\")\n",
        "\n",
        "if not NGROK_TOKEN:\n",
        "    raise RuntimeError(\"Missing NGROK_AUTH_TOKEN env var. Did you run the getpass cell?\")\n",
        "\n",
        "ngrok.set_auth_token(NGROK_TOKEN)\n",
        "print(\"ngrok token loaded from environment.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sqxaFHHYtCzT",
        "outputId": "d8df3d13-11b0-4b3d-ba74-5109c8a8c405"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ngrok token loaded from environment.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "print(\"Loaded secret:\", bool(os.environ.get(\"NGROK_AUTH_TOKEN\")))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QzbW4lK9y9au",
        "outputId": "0b2cbfa0-0017-4fa3-8a19-04d062e3d757"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded secret: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf chroma_db\n"
      ],
      "metadata": {
        "id": "gb7Kh_KnLJtX"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RAG Pipeline"
      ],
      "metadata": {
        "id": "y_ayGzvlLPPH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile main.py\n",
        "\"\"\"\n",
        "main.py\n",
        "Multi-Modal RAG over PDF documents using:\n",
        "- HuggingFace CLIP for unified multi-modal embeddings (text + images)\n",
        "- HuggingFace FLAN-T5 for generation\n",
        "- ChromaDB (new API, PersistentClient) as vector store\n",
        "- FastAPI as API layer\n",
        "\"\"\"\n",
        "\n",
        "import io\n",
        "import os\n",
        "import re\n",
        "import uuid\n",
        "from typing import List, Dict, Optional\n",
        "\n",
        "import fitz  # PyMuPDF\n",
        "from PIL import Image\n",
        "import pytesseract\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "from fastapi import FastAPI, File, UploadFile, Form\n",
        "from fastapi.middleware.cors import CORSMiddleware\n",
        "from pydantic import BaseModel\n",
        "from transformers import CLIPProcessor, CLIPModel, AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "\n",
        "import chromadb\n",
        "from chromadb import PersistentClient\n",
        "\n",
        "# Configuration\n",
        "\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "CLIP_MODEL_NAME = \"openai/clip-vit-base-patch32\"\n",
        "GEN_MODEL_NAME = \"google/flan-t5-base\"  # can change to -small if GPU RAM is low\n",
        "\n",
        "CHROMA_DIR = \"./chroma_db\"\n",
        "COLLECTION_NAME = \"multi_modal_docs\"\n",
        "IMAGE_DIR = \"./pdf_images\"\n",
        "os.makedirs(IMAGE_DIR, exist_ok=True)\n",
        "\n",
        "\n",
        "\n",
        "# Model loader (lazy singletons)\n",
        "\n",
        "class ModelRegistry:\n",
        "    _clip_model = None\n",
        "    _clip_processor = None\n",
        "    _tokenizer = None\n",
        "    _gen_model = None\n",
        "\n",
        "    @classmethod\n",
        "    def get_clip(cls):\n",
        "        if cls._clip_model is None or cls._clip_processor is None:\n",
        "            print(\"Loading CLIP model:\", CLIP_MODEL_NAME)\n",
        "            cls._clip_model = CLIPModel.from_pretrained(CLIP_MODEL_NAME).to(DEVICE)\n",
        "            cls._clip_processor = CLIPProcessor.from_pretrained(CLIP_MODEL_NAME)\n",
        "        return cls._clip_model, cls._clip_processor\n",
        "\n",
        "    @classmethod\n",
        "    def get_generator(cls):\n",
        "        if cls._tokenizer is None or cls._gen_model is None:\n",
        "            print(\"Loading generator model:\", GEN_MODEL_NAME)\n",
        "            cls._tokenizer = AutoTokenizer.from_pretrained(GEN_MODEL_NAME)\n",
        "            cls._gen_model = AutoModelForSeq2SeqLM.from_pretrained(GEN_MODEL_NAME).to(DEVICE)\n",
        "        return cls._tokenizer, cls._gen_model\n",
        "\n",
        "\n",
        "\n",
        "# Chroma client & collection (NEW API)\n",
        "\n",
        "\n",
        "client: PersistentClient = chromadb.PersistentClient(path=CHROMA_DIR)\n",
        "collection = client.get_or_create_collection(name=COLLECTION_NAME)\n",
        "\n",
        "\n",
        "\n",
        "# Embedding helpers (CLIP)\n",
        "\n",
        "\n",
        "def encode_text_clip(texts: List[str]) -> np.ndarray:\n",
        "    \"\"\"Encode a list of texts into CLIP text embeddings.\"\"\"\n",
        "    clip_model, clip_processor = ModelRegistry.get_clip()\n",
        "    inputs = clip_processor(text=texts, return_tensors=\"pt\", padding=True, truncation=True).to(DEVICE)\n",
        "    with torch.no_grad():\n",
        "        text_embs = clip_model.get_text_features(**inputs)\n",
        "    text_embs = text_embs / text_embs.norm(dim=-1, keepdim=True)\n",
        "    return text_embs.cpu().numpy()\n",
        "\n",
        "\n",
        "def encode_images_clip(image_paths: List[str]) -> np.ndarray:\n",
        "    \"\"\"Encode a list of image file paths into CLIP image embeddings.\"\"\"\n",
        "    clip_model, clip_processor = ModelRegistry.get_clip()\n",
        "    images = [Image.open(p).convert(\"RGB\") for p in image_paths]\n",
        "    inputs = clip_processor(images=images, return_tensors=\"pt\", padding=True).to(DEVICE)\n",
        "    with torch.no_grad():\n",
        "        img_embs = clip_model.get_image_features(**inputs)\n",
        "    img_embs = img_embs / img_embs.norm(dim=-1, keepdim=True)\n",
        "    return img_embs.cpu().numpy()\n",
        "\n",
        "\n",
        "\n",
        "# PDF ingestion: text + images + OCR + simple captions\n",
        "\n",
        "\n",
        "def extract_page_text(page) -> str:\n",
        "    \"\"\"Simple full-page text extraction.\"\"\"\n",
        "    return page.get_text(\"text\")\n",
        "\n",
        "\n",
        "def find_chart_captions(page_text: str) -> List[str]:\n",
        "    \"\"\"Find lines that look like figure/chart captions.\"\"\"\n",
        "    captions = []\n",
        "    for line in page_text.splitlines():\n",
        "        if re.match(r\"^\\s*(Figure|Chart|Exhibit)\\b\", line.strip(), flags=re.IGNORECASE):\n",
        "            captions.append(line.strip())\n",
        "    return captions\n",
        "\n",
        "\n",
        "def ingest_pdf_bytes(doc_id: str, file_bytes: bytes) -> List[Dict]:\n",
        "    \"\"\"\n",
        "    Ingest a single PDF from bytes.\n",
        "    Returns a list of 'items', each with modality and metadata BEFORE chunking/embedding.\n",
        "    \"\"\"\n",
        "    items: List[Dict] = []\n",
        "    doc = fitz.open(stream=file_bytes, filetype=\"pdf\")\n",
        "\n",
        "    for page_index in range(len(doc)):\n",
        "        page = doc[page_index]\n",
        "        page_number = page_index + 1\n",
        "        page_text = extract_page_text(page)\n",
        "        page_text = page_text.strip()\n",
        "\n",
        "        section_title = f\"Page {page_number}\"  # simple section label\n",
        "\n",
        "        # ---- TEXT ITEM ----\n",
        "        if page_text:\n",
        "            items.append({\n",
        "                \"id\": f\"{doc_id}_text_p{page_number}\",\n",
        "                \"doc_id\": doc_id,\n",
        "                \"modality\": \"text\",\n",
        "                \"content\": page_text,\n",
        "                \"page_number\": page_number,\n",
        "                \"section\": section_title,\n",
        "                \"extra\": {},\n",
        "            })\n",
        "\n",
        "        # ---- IMAGE ITEMS ----\n",
        "        image_list = page.get_images(full=True)\n",
        "        captions = find_chart_captions(page_text)\n",
        "        caption_str = \" | \".join(captions) if captions else \"\"\n",
        "\n",
        "        for img_idx, img in enumerate(image_list):\n",
        "            xref = img[0]\n",
        "            base_image = doc.extract_image(xref)\n",
        "            image_bytes = base_image[\"image\"]\n",
        "            pil_img = Image.open(io.BytesIO(image_bytes)).convert(\"RGB\")\n",
        "\n",
        "            img_filename = f\"{doc_id}_page{page_number}_img{img_idx}.png\"\n",
        "            img_path = os.path.join(IMAGE_DIR, img_filename)\n",
        "            pil_img.save(img_path)\n",
        "\n",
        "            ocr_text = pytesseract.image_to_string(pil_img)\n",
        "\n",
        "            items.append({\n",
        "                \"id\": f\"{doc_id}_img_p{page_number}_{img_idx}\",\n",
        "                \"doc_id\": doc_id,\n",
        "                \"modality\": \"image\",\n",
        "                \"content\": ocr_text.strip(),  # used in LLM context\n",
        "                \"page_number\": page_number,\n",
        "                \"section\": section_title,\n",
        "                \"extra\": {\n",
        "                    \"image_path\": img_path,\n",
        "                    \"caption\": caption_str,\n",
        "                },\n",
        "            })\n",
        "\n",
        "    doc.close()\n",
        "    return items\n",
        "\n",
        "\n",
        "\n",
        "# Smart Hybrid Chunking (Semantic + Structural)\n",
        "\n",
        "\n",
        "def structural_split(text: str) -> List[str]:\n",
        "    \"\"\"\n",
        "    Detect structural boundaries (section headers, numbered headings, all caps, etc.).\n",
        "    Returns a list of larger blocks split by structure.\n",
        "    \"\"\"\n",
        "    lines = text.split(\"\\n\")\n",
        "    chunks = []\n",
        "    buffer = []\n",
        "\n",
        "    for line in lines:\n",
        "        stripped = line.strip()\n",
        "        if not stripped:\n",
        "            buffer.append(line)\n",
        "            continue\n",
        "\n",
        "        is_heading = (\n",
        "            re.match(r\"^\\d+(\\.\\d+)*\\s\", stripped) or         # 1.  / 1.1 / 2.3.4\n",
        "            re.match(r\"^[A-Z][A-Z\\s\\-]{6,}$\", stripped) or   # ALL CAPS headings\n",
        "            re.match(r\"^[A-Za-z].+:\\s*$\", stripped) or       # Title:\n",
        "            re.match(r\"^(Conclusion|Summary|Overview)\\b\", stripped, re.I)\n",
        "        )\n",
        "\n",
        "        # New section detected → flush buffer\n",
        "        if is_heading and buffer:\n",
        "            chunks.append(\"\\n\".join(buffer))\n",
        "            buffer = [line]\n",
        "        else:\n",
        "            buffer.append(line)\n",
        "\n",
        "    if buffer:\n",
        "        chunks.append(\"\\n\".join(buffer))\n",
        "\n",
        "    return chunks\n",
        "\n",
        "\n",
        "def semantic_chunk_block(text: str, max_tokens: int = 1200, threshold: float = 0.65) -> List[str]:\n",
        "    \"\"\"\n",
        "    Split a text block into semantic chunks using sentence embeddings.\n",
        "    \"\"\"\n",
        "    from nltk.tokenize import sent_tokenize\n",
        "\n",
        "    sentences = sent_tokenize(text)\n",
        "    if len(sentences) <= 1:\n",
        "        return [text]\n",
        "\n",
        "    # Encode each sentence with CLIP embeddings\n",
        "    embeddings = encode_text_clip(sentences)\n",
        "    embeddings = embeddings / np.linalg.norm(embeddings, axis=1, keepdims=True)\n",
        "\n",
        "    chunks = []\n",
        "    current = [sentences[0]]\n",
        "    current_len = len(sentences[0])\n",
        "\n",
        "    for i in range(1, len(sentences)):\n",
        "        sim = float(np.dot(embeddings[i], embeddings[i - 1]))\n",
        "\n",
        "        # Low similarity OR chunk too long → start new chunk\n",
        "        if sim < threshold or current_len > max_tokens:\n",
        "            chunks.append(\" \".join(current))\n",
        "            current = [sentences[i]]\n",
        "            current_len = len(sentences[i])\n",
        "        else:\n",
        "            current.append(sentences[i])\n",
        "            current_len += len(sentences[i])\n",
        "\n",
        "    # final chunk\n",
        "    chunks.append(\" \".join(current))\n",
        "    return chunks\n",
        "\n",
        "\n",
        "def chunk_text(text: str) -> List[str]:\n",
        "    \"\"\"\n",
        "    Hybrid chunking:\n",
        "    1. Split using document structure (headings, sections).\n",
        "    2. Within each block, perform semantic chunking.\n",
        "    \"\"\"\n",
        "    structural_blocks = structural_split(text)\n",
        "    final_chunks: List[str] = []\n",
        "\n",
        "    for block in structural_blocks:\n",
        "        block = block.strip()\n",
        "        if not block:\n",
        "            continue\n",
        "        sem_chunks = semantic_chunk_block(block)\n",
        "        final_chunks.extend(sem_chunks)\n",
        "\n",
        "    return final_chunks\n",
        "\n",
        "\n",
        "def items_to_chunks(items: List[Dict]) -> List[Dict]:\n",
        "    \"\"\"\n",
        "    Convert per-page items into smaller chunks for embedding.\n",
        "    Text → hybrid (structural + semantic).\n",
        "    Image → OCR + caption stays together.\n",
        "    \"\"\"\n",
        "    chunks: List[Dict] = []\n",
        "\n",
        "    for it in items:\n",
        "        if it[\"modality\"] == \"text\":\n",
        "            text_chunks = chunk_text(it[\"content\"])\n",
        "            for idx, ch in enumerate(text_chunks):\n",
        "                chunks.append({\n",
        "                    \"id\": f\"{it['id']}_chunk{idx}\",\n",
        "                    \"doc_id\": it[\"doc_id\"],\n",
        "                    \"modality\": \"text\",\n",
        "                    \"content\": ch,\n",
        "                    \"page_number\": it[\"page_number\"],\n",
        "                    \"section\": it.get(\"section\") or \"\",\n",
        "                    \"extra\": {},  # not used for text in metadata; keep flat\n",
        "                })\n",
        "        elif it[\"modality\"] == \"image\":\n",
        "            combined = it[\"content\"]\n",
        "            caption = it[\"extra\"].get(\"caption\")\n",
        "            if caption:\n",
        "                combined = f\"{caption}\\n\\n{combined}\"\n",
        "\n",
        "            chunks.append({\n",
        "                \"id\": it[\"id\"],\n",
        "                \"doc_id\": it[\"doc_id\"],\n",
        "                \"modality\": \"image\",\n",
        "                \"content\": combined,\n",
        "                \"page_number\": it[\"page_number\"],\n",
        "                \"section\": it.get(\"section\") or \"\",\n",
        "                \"extra\": it.get(\"extra\", {}),\n",
        "            })\n",
        "\n",
        "    return chunks\n",
        "\n",
        "\n",
        "\n",
        "# Indexing (Chroma + CLIP)\n",
        "\n",
        "\n",
        "def index_chunks(chunks: List[Dict]):\n",
        "    \"\"\"\n",
        "    Index all chunks in unified multi-modal space.\n",
        "    Text-like: CLIP text encoder.\n",
        "    Images: CLIP image encoder, document string is OCR+caption.\n",
        "    \"\"\"\n",
        "    if not chunks:\n",
        "        return\n",
        "\n",
        "    text_like = [c for c in chunks if c[\"modality\"] != \"image\"]\n",
        "    image_like = [c for c in chunks if c[\"modality\"] == \"image\"]\n",
        "\n",
        "    # Text-like chunks\n",
        "    if text_like:\n",
        "        texts = [c[\"content\"] for c in text_like]\n",
        "        text_embs = encode_text_clip(texts)\n",
        "        collection.add(\n",
        "            ids=[c[\"id\"] for c in text_like],\n",
        "            embeddings=text_embs.tolist(),\n",
        "            documents=texts,\n",
        "            metadatas=[\n",
        "                {\n",
        "                    \"doc_id\": str(c[\"doc_id\"]),\n",
        "                    \"modality\": str(c[\"modality\"]),\n",
        "                    \"page_number\": int(c[\"page_number\"]),\n",
        "                    \"section\": str(c.get(\"section\") or \"\"),\n",
        "                    # text chunks don't have image data\n",
        "                    \"image_path\": \"\",\n",
        "                    \"caption\": \"\",\n",
        "                }\n",
        "                for c in text_like\n",
        "            ],\n",
        "        )\n",
        "\n",
        "    # Image chunks\n",
        "    if image_like:\n",
        "        image_paths = [c.get(\"extra\", {}).get(\"image_path\", \"\") for c in image_like]\n",
        "        img_embs = encode_images_clip(image_paths)\n",
        "        docs_for_llm = [c[\"content\"] for c in image_like]  # OCR+caption\n",
        "        collection.add(\n",
        "            ids=[c[\"id\"] for c in image_like],\n",
        "            embeddings=img_embs.tolist(),\n",
        "            documents=docs_for_llm,\n",
        "            metadatas=[\n",
        "                {\n",
        "                    \"doc_id\": str(c[\"doc_id\"]),\n",
        "                    \"modality\": str(c[\"modality\"]),\n",
        "                    \"page_number\": int(c[\"page_number\"]),\n",
        "                    \"section\": str(c.get(\"section\") or \"\"),\n",
        "                    \"image_path\": c.get(\"extra\", {}).get(\"image_path\", \"\"),\n",
        "                    \"caption\": c.get(\"extra\", {}).get(\"caption\", \"\"),\n",
        "                }\n",
        "                for c in image_like\n",
        "            ],\n",
        "        )\n",
        "\n",
        "    print(f\"Indexed {len(chunks)} chunks (text-like={len(text_like)}, image={len(image_like)})\")\n",
        "\n",
        "# -----------------------------\n",
        "# Retrieval & RAG\n",
        "# -----------------------------\n",
        "\n",
        "def retrieve_chunks(query: str, doc_id: str, top_k: int = 8) -> List[Dict]:\n",
        "    \"\"\"Retrieve top-k multi-modal chunks for a given query and doc_id.\"\"\"\n",
        "    q_emb = encode_text_clip([query])\n",
        "    results = collection.query(\n",
        "        query_embeddings=q_emb.tolist(),\n",
        "        n_results=top_k,\n",
        "        where={\"doc_id\": doc_id},\n",
        "    )\n",
        "\n",
        "    if not results[\"ids\"]:\n",
        "        return []\n",
        "\n",
        "    retrieved = []\n",
        "    for i in range(len(results[\"ids\"][0])):\n",
        "        retrieved.append({\n",
        "            \"id\": results[\"ids\"][0][i],\n",
        "            \"content\": results[\"documents\"][0][i],\n",
        "            \"metadata\": results[\"metadatas\"][0][i],\n",
        "            \"distance\": results[\"distances\"][0][i] if \"distances\" in results else None,\n",
        "        })\n",
        "    return retrieved\n",
        "\n",
        "\n",
        "def format_context_for_prompt(chunks: List[Dict]) -> str:\n",
        "    \"\"\"Produce LLM context string with explicit source tags.\"\"\"\n",
        "    blocks = []\n",
        "    for idx, c in enumerate(chunks, start=1):\n",
        "        m = c[\"metadata\"]\n",
        "        page = m.get(\"page_number\", \"?\")\n",
        "        section = m.get(\"section\", \"Unknown section\")\n",
        "        modality = m.get(\"modality\", \"text\")\n",
        "        tag = f\"[SOURCE {idx} – page {page}, section: {section}, modality: {modality}]\"\n",
        "        content = c[\"content\"].strip()\n",
        "        if len(content) > 1200:\n",
        "            content = content[:1200] + \"... [truncated]\"\n",
        "        blocks.append(f\"{tag}\\n{content}\\n\")\n",
        "    return \"\\n\\n\".join(blocks)\n",
        "\n",
        "\n",
        "def build_rag_prompt(question: str, chunks: List[Dict]) -> str:\n",
        "    context = format_context_for_prompt(chunks)\n",
        "    prompt = f\"\"\"\n",
        "You are a QA assistant for IMF-style financial and policy documents.\n",
        "\n",
        "You are given context extracted from:\n",
        "- Text paragraphs\n",
        "- Tables (as text)\n",
        "- Images and charts (represented via OCR text and captions)\n",
        "\n",
        "Context:\n",
        "{context}\n",
        "\n",
        "Instructions:\n",
        "- Answer the user's question ONLY using the context above.\n",
        "- If the answer is not in the context, say you don't know.\n",
        "- Always include citations using the exact tags like [SOURCE i – page X, section: Y, modality: Z].\n",
        "\n",
        "Question: {question}\n",
        "\n",
        "Answer:\n",
        "\"\"\"\n",
        "    # Trim if too long\n",
        "    if len(prompt) > 6000:\n",
        "        prompt = prompt[-6000:]\n",
        "    return prompt\n",
        "\n",
        "\n",
        "def call_llm(prompt: str, max_new_tokens: int = 256) -> str:\n",
        "    tokenizer, gen_model = ModelRegistry.get_generator()\n",
        "    inputs = tokenizer(\n",
        "        prompt,\n",
        "        return_tensors=\"pt\",\n",
        "        truncation=True,\n",
        "        max_length=2048,\n",
        "    ).to(DEVICE)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = gen_model.generate(\n",
        "            **inputs,\n",
        "            max_new_tokens=max_new_tokens,\n",
        "            do_sample=False,\n",
        "            num_beams=4,\n",
        "        )\n",
        "\n",
        "    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "\n",
        "def rag_answer(question: str, doc_id: str, top_k: int = 8) -> Dict:\n",
        "    chunks = retrieve_chunks(question, doc_id, top_k=top_k)\n",
        "    if not chunks:\n",
        "        return {\n",
        "            \"answer\": \"I couldn't find any relevant context for this document.\",\n",
        "            \"sources\": [],\n",
        "        }\n",
        "    prompt = build_rag_prompt(question, chunks)\n",
        "    answer = call_llm(prompt)\n",
        "    return {\n",
        "        \"answer\": answer,\n",
        "        \"sources\": chunks,\n",
        "    }\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# FastAPI models & app\n",
        "# -----------------------------\n",
        "\n",
        "class QueryRequest(BaseModel):\n",
        "    doc_id: str\n",
        "    question: str\n",
        "    top_k: Optional[int] = 8\n",
        "\n",
        "\n",
        "class QueryResponse(BaseModel):\n",
        "    answer: str\n",
        "    sources: List[Dict]\n",
        "\n",
        "\n",
        "class IngestResponse(BaseModel):\n",
        "    doc_id: str\n",
        "    num_items: int\n",
        "    num_chunks: int\n",
        "\n",
        "\n",
        "app = FastAPI(title=\"Multi-Modal RAG over Documents\")\n",
        "\n",
        "app.add_middleware(\n",
        "    CORSMiddleware,\n",
        "    allow_origins=[\"*\"],\n",
        "    allow_credentials=True,\n",
        "    allow_methods=[\"*\"],\n",
        "    allow_headers=[\"*\"],\n",
        ")\n",
        "\n",
        "\n",
        "@app.get(\"/\")\n",
        "async def root():\n",
        "    return {\"status\": \"ok\", \"message\": \"Multi-Modal RAG API is running.\"}\n",
        "\n",
        "\n",
        "@app.post(\"/ingest\", response_model=IngestResponse)\n",
        "async def ingest_endpoint(\n",
        "    file: UploadFile = File(...),\n",
        "    doc_id: Optional[str] = Form(None),\n",
        "):\n",
        "    \"\"\"Ingest a PDF into the RAG system.\"\"\"\n",
        "    if doc_id is None or not doc_id.strip():\n",
        "        base = os.path.splitext(file.filename)[0] if file.filename else \"doc\"\n",
        "        doc_id = f\"{base}_{uuid.uuid4().hex[:8]}\"\n",
        "\n",
        "    file_bytes = await file.read()\n",
        "\n",
        "    items = ingest_pdf_bytes(doc_id, file_bytes)\n",
        "    chunks = items_to_chunks(items)\n",
        "    index_chunks(chunks)\n",
        "\n",
        "    return IngestResponse(\n",
        "        doc_id=doc_id,\n",
        "        num_items=len(items),\n",
        "        num_chunks=len(chunks),\n",
        "    )\n",
        "\n",
        "\n",
        "@app.post(\"/query\", response_model=QueryResponse)\n",
        "async def query_endpoint(req: QueryRequest):\n",
        "    \"\"\"Ask a question about a previously ingested document.\"\"\"\n",
        "    result = rag_answer(req.question, req.doc_id, top_k=req.top_k or 8)\n",
        "    return QueryResponse(\n",
        "        answer=result[\"answer\"],\n",
        "        sources=result[\"sources\"],\n",
        "    )\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    import uvicorn\n",
        "    uvicorn.run(\"main:app\", host=\"0.0.0.0\", port=8000, reload=True)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B9SDUqonfdVJ",
        "outputId": "dfea4c31-37b8-41b5-9ff5-767349e8fbe8"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing main.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from fastapi.responses import HTMLResponse\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "@app.get(\"/qa\", response_class=HTMLResponse)\n",
        "async def qa_frontend():\n",
        "    \"\"\"Simple HTML frontend for uploading a PDF and asking questions.\"\"\"\n",
        "    return \"\"\"\n",
        "<!DOCTYPE html>\n",
        "<html>\n",
        "<head>\n",
        "  <meta charset=\"UTF-8\" />\n",
        "  <title>Multi-Modal RAG QA</title>\n",
        "  <style>\n",
        "    body {\n",
        "      font-family: system-ui, -apple-system, BlinkMacSystemFont, \"Segoe UI\", sans-serif;\n",
        "      max-width: 900px;\n",
        "      margin: 20px auto;\n",
        "      padding: 0 16px;\n",
        "      background: #f5f5f5;\n",
        "    }\n",
        "    h1 {\n",
        "      text-align: center;\n",
        "    }\n",
        "    .card {\n",
        "      background: white;\n",
        "      padding: 16px 20px;\n",
        "      margin-bottom: 20px;\n",
        "      border-radius: 12px;\n",
        "      box-shadow: 0 2px 6px rgba(0,0,0,0.08);\n",
        "    }\n",
        "    label {\n",
        "      font-weight: 600;\n",
        "      display: block;\n",
        "      margin-bottom: 4px;\n",
        "    }\n",
        "    input[type=\"text\"], textarea {\n",
        "      width: 100%;\n",
        "      padding: 8px 10px;\n",
        "      border-radius: 8px;\n",
        "      border: 1px solid #ccc;\n",
        "      box-sizing: border-box;\n",
        "      margin-bottom: 10px;\n",
        "      font-family: inherit;\n",
        "      font-size: 14px;\n",
        "    }\n",
        "    input[type=\"file\"] {\n",
        "      margin: 8px 0 12px;\n",
        "    }\n",
        "    button {\n",
        "      padding: 8px 16px;\n",
        "      border-radius: 999px;\n",
        "      border: none;\n",
        "      cursor: pointer;\n",
        "      font-weight: 600;\n",
        "      font-size: 14px;\n",
        "      margin-top: 4px;\n",
        "    }\n",
        "    button.primary {\n",
        "      background: #2563eb;\n",
        "      color: white;\n",
        "    }\n",
        "    button.secondary {\n",
        "      background: #e5e7eb;\n",
        "      color: #111827;\n",
        "    }\n",
        "    .row {\n",
        "      display: flex;\n",
        "      gap: 8px;\n",
        "      align-items: center;\n",
        "    }\n",
        "    .row input[type=\"text\"] {\n",
        "      flex: 1;\n",
        "      margin-bottom: 0;\n",
        "    }\n",
        "    .pill {\n",
        "      display: inline-block;\n",
        "      padding: 2px 8px;\n",
        "      font-size: 12px;\n",
        "      border-radius: 999px;\n",
        "      background: #e5e7eb;\n",
        "      margin-right: 4px;\n",
        "    }\n",
        "    pre {\n",
        "      white-space: pre-wrap;\n",
        "      background: #111827;\n",
        "      color: #e5e7eb;\n",
        "      padding: 12px;\n",
        "      border-radius: 8px;\n",
        "      font-size: 13px;\n",
        "      max-height: 300px;\n",
        "      overflow: auto;\n",
        "    }\n",
        "    #status {\n",
        "      margin-top: 6px;\n",
        "      font-size: 13px;\n",
        "      color: #4b5563;\n",
        "    }\n",
        "    .source {\n",
        "      background: #f9fafb;\n",
        "      padding: 8px 10px;\n",
        "      border-radius: 8px;\n",
        "      margin-bottom: 6px;\n",
        "      font-size: 13px;\n",
        "    }\n",
        "    .source-header {\n",
        "      font-weight: 600;\n",
        "      margin-bottom: 4px;\n",
        "    }\n",
        "  </style>\n",
        "</head>\n",
        "<body>\n",
        "  <h1>📄 Multi-Modal RAG QA</h1>\n",
        "\n",
        "  <!-- Upload / ingest card -->\n",
        "  <div class=\"card\">\n",
        "    <h2>1. Upload Document</h2>\n",
        "    <label for=\"pdfFile\">PDF file</label>\n",
        "    <input type=\"file\" id=\"pdfFile\" accept=\"application/pdf\" />\n",
        "\n",
        "    <label for=\"docIdInput\">Document ID (optional)</label>\n",
        "    <div class=\"row\">\n",
        "      <input type=\"text\" id=\"docIdInput\" placeholder=\"Leave empty to auto-generate\" />\n",
        "      <button class=\"secondary\" type=\"button\" onclick=\"clearDocId()\">Clear</button>\n",
        "    </div>\n",
        "\n",
        "    <button class=\"primary\" type=\"button\" onclick=\"uploadPdf()\">Ingest PDF</button>\n",
        "    <div id=\"status\"></div>\n",
        "    <div id=\"currentDoc\"></div>\n",
        "  </div>\n",
        "\n",
        "  <!-- QA card -->\n",
        "  <div class=\"card\">\n",
        "    <h2>2. Ask a Question</h2>\n",
        "    <label for=\"questionInput\">Question</label>\n",
        "    <textarea id=\"questionInput\" rows=\"3\" placeholder=\"Example: What is the GDP growth outlook for next year?\"></textarea>\n",
        "\n",
        "    <div class=\"row\">\n",
        "      <label for=\"topKInput\" style=\"margin: 0;\">Top-k chunks:</label>\n",
        "      <input type=\"text\" id=\"topKInput\" value=\"8\" style=\"max-width: 80px;\" />\n",
        "      <button class=\"primary\" type=\"button\" onclick=\"askQuestion()\">Ask</button>\n",
        "    </div>\n",
        "\n",
        "    <div id=\"answerBox\" style=\"margin-top: 12px;\"></div>\n",
        "    <div id=\"sourcesBox\" style=\"margin-top: 10px;\"></div>\n",
        "  </div>\n",
        "\n",
        "  <script>\n",
        "    const baseUrl = window.location.origin;  // same host as FastAPI\n",
        "\n",
        "    function setStatus(msg) {\n",
        "      document.getElementById(\"status\").innerText = msg || \"\";\n",
        "    }\n",
        "\n",
        "    function setCurrentDoc(docId) {\n",
        "      if (!docId) {\n",
        "        document.getElementById(\"currentDoc\").innerHTML = \"\";\n",
        "        return;\n",
        "      }\n",
        "      document.getElementById(\"currentDoc\").innerHTML =\n",
        "        '<span class=\"pill\">Current doc_id:</span> <code>' + docId + '</code>';\n",
        "    }\n",
        "\n",
        "    function clearDocId() {\n",
        "      document.getElementById(\"docIdInput\").value = \"\";\n",
        "      setCurrentDoc(\"\");\n",
        "    }\n",
        "\n",
        "    async function uploadPdf() {\n",
        "      const fileInput = document.getElementById(\"pdfFile\");\n",
        "      const docIdInput = document.getElementById(\"docIdInput\");\n",
        "\n",
        "      if (fileInput.files.length === 0) {\n",
        "        alert(\"Please select a PDF file first.\");\n",
        "        return;\n",
        "      }\n",
        "\n",
        "      const file = fileInput.files[0];\n",
        "      const formData = new FormData();\n",
        "      formData.append(\"file\", file);\n",
        "      if (docIdInput.value.trim() !== \"\") {\n",
        "        formData.append(\"doc_id\", docIdInput.value.trim());\n",
        "      }\n",
        "\n",
        "      setStatus(\"Uploading and ingesting PDF...\");\n",
        "\n",
        "      try {\n",
        "        const resp = await fetch(baseUrl + \"/ingest\", {\n",
        "          method: \"POST\",\n",
        "          body: formData\n",
        "        });\n",
        "\n",
        "        if (!resp.ok) {\n",
        "          const text = await resp.text();\n",
        "          console.error(\"Ingest error:\", text);\n",
        "          setStatus(\"Error during ingest: \" + resp.status + \" \" + resp.statusText);\n",
        "          return;\n",
        "        }\n",
        "\n",
        "        const data = await resp.json();\n",
        "        console.log(\"Ingest response:\", data);\n",
        "        setStatus(\"Ingestion complete. Chunks indexed: \" + data.num_chunks);\n",
        "        docIdInput.value = data.doc_id;\n",
        "        setCurrentDoc(data.doc_id);\n",
        "      } catch (err) {\n",
        "        console.error(err);\n",
        "        setStatus(\"Error during ingest: \" + err);\n",
        "      }\n",
        "    }\n",
        "\n",
        "    async function askQuestion() {\n",
        "      const docId = document.getElementById(\"docIdInput\").value.trim();\n",
        "      const question = document.getElementById(\"questionInput\").value.trim();\n",
        "      const topKStr = document.getElementById(\"topKInput\").value.trim();\n",
        "\n",
        "      if (!docId) {\n",
        "        alert(\"Please upload a document first (or specify doc_id).\");\n",
        "        return;\n",
        "      }\n",
        "      if (!question) {\n",
        "        alert(\"Please enter a question.\");\n",
        "        return;\n",
        "      }\n",
        "\n",
        "      const topK = parseInt(topKStr || \"8\", 10);\n",
        "\n",
        "      setStatus(\"Asking question...\");\n",
        "      document.getElementById(\"answerBox\").innerHTML = \"\";\n",
        "      document.getElementById(\"sourcesBox\").innerHTML = \"\";\n",
        "\n",
        "      try {\n",
        "        const resp = await fetch(baseUrl + \"/query\", {\n",
        "          method: \"POST\",\n",
        "          headers: { \"Content-Type\": \"application/json\" },\n",
        "          body: JSON.stringify({\n",
        "            doc_id: docId,\n",
        "            question: question,\n",
        "            top_k: topK\n",
        "          }),\n",
        "        });\n",
        "\n",
        "        if (!resp.ok) {\n",
        "          const text = await resp.text();\n",
        "          console.error(\"Query error:\", text);\n",
        "          setStatus(\"Error during query: \" + resp.status + \" \" + resp.statusText);\n",
        "          return;\n",
        "        }\n",
        "\n",
        "        const data = await resp.json();\n",
        "        console.log(\"Query response:\", data);\n",
        "        setStatus(\"Done.\");\n",
        "\n",
        "        // Show answer\n",
        "        document.getElementById(\"answerBox\").innerHTML =\n",
        "          \"<h3>Answer</h3><pre>\" + (data.answer || \"[no answer]\") + \"</pre>\";\n",
        "\n",
        "        // Show sources\n",
        "        const sourcesDiv = document.getElementById(\"sourcesBox\");\n",
        "        sourcesDiv.innerHTML = \"<h3>Sources</h3>\";\n",
        "        if (!data.sources || data.sources.length === 0) {\n",
        "          sourcesDiv.innerHTML += \"<p>No sources returned.</p>\";\n",
        "        } else {\n",
        "          data.sources.forEach((s, idx) => {\n",
        "            const md = s.metadata || {};\n",
        "            const src = document.createElement(\"div\");\n",
        "            src.className = \"source\";\n",
        "            src.innerHTML =\n",
        "              '<div class=\"source-header\">SOURCE ' + (idx + 1) +\n",
        "              \" – page \" + (md.page_number ?? \"?\") +\n",
        "              ', modality: ' + (md.modality ?? \"?\") +\n",
        "              ', section: ' + (md.section || \"\") +\n",
        "              \"</div>\" +\n",
        "              \"<div>\" + (s.content ? s.content.substring(0, 400) : \"\") +\n",
        "              (s.content && s.content.length > 400 ? \"...\" : \"\") +\n",
        "              \"</div>\";\n",
        "            sourcesDiv.appendChild(src);\n",
        "          });\n",
        "        }\n",
        "\n",
        "      } catch (err) {\n",
        "        console.error(err);\n",
        "        setStatus(\"Error during query: \" + err);\n",
        "      }\n",
        "    }\n",
        "  </script>\n",
        "</body>\n",
        "</html>\n",
        "    \"\"\"\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "bFiQ3iZGuicS"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#FASTAPI+ngrok Building"
      ],
      "metadata": {
        "id": "El33aGfKSUpV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nest_asyncio, threading, uvicorn\n",
        "from pyngrok import ngrok\n",
        "from main import app  # our FastAPI app\n",
        "\n",
        "nest_asyncio.apply()\n",
        "\n",
        "# Use the token you already stored in NGROK_AUTH_TOKEN\n",
        "from os import environ\n",
        "token = environ.get(\"NGROK_AUTH_TOKEN\")\n",
        "if not token:\n",
        "    raise RuntimeError(\"NGROK_AUTH_TOKEN env var not set. Run the getpass setup cell first.\")\n",
        "\n",
        "ngrok.set_auth_token(token)\n",
        "\n",
        "# Open public tunnel\n",
        "public_tunnel = ngrok.connect(8000, \"http\")\n",
        "public_url = public_tunnel.public_url\n",
        "print(\"Public URL:\", public_url)\n",
        "\n",
        "# Start FastAPI server in background thread\n",
        "def run_server():\n",
        "    uvicorn.run(app, host=\"0.0.0.0\", port=8000, log_level=\"info\")\n",
        "\n",
        "server_thread = threading.Thread(target=run_server, daemon=True)\n",
        "server_thread.start()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X2GzIurC02Lo",
        "outputId": "b17b53e6-b2c2-4c22-f600-8b77a156c868"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Public URL: https://heavily-tubbier-tajuana.ngrok-free.dev\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:     Started server process [1212]\n",
            "INFO:     Waiting for application startup.\n",
            "INFO:     Application startup complete.\n"
          ]
        }
      ]
    }
  ]
}